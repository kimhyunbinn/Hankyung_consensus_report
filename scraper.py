import os
import requests
import telegram
import asyncio
import re
import fitz
import json
from bs4 import BeautifulSoup
from io import BytesIO

# --- ì„¤ì • (GitHub Secrets í™˜ê²½ ë³€ìˆ˜) ---
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
BASE_URL = "https://consensus.hankyung.com"

def get_summary_rest(text):
    if not GEMINI_API_KEY: return "âŒ í‚¤ ë¯¸ì„¤ì •"
    # ê°€ì¥ í‘œì¤€ì ì¸ v1beta ê²½ë¡œ ì‚¬ìš©
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    
    payload = {
        "contents": [{"parts": [{"text": f"ë‹¹ì‹ ì€ ê¸ˆìœµ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¦¬í¬íŠ¸ì˜ í•µì‹¬ íˆ¬ì í¬ì¸íŠ¸ 3ê°€ì§€ë¥¼ ì „ë¬¸ì ì¸ ì–´ì¡°ë¡œ ìš”ì•½í•´ì¤˜:\n\n{text[:7000]}"}]}]
    }
    
    try:
        res = requests.post(url, json=payload, timeout=20)
        if res.status_code == 200:
            return res.json()['candidates'][0]['content']['parts'][0]['text'].strip()
        return f"âŒ ìš”ì•½ ì‹¤íŒ¨ (Code {res.status_code})\n{res.text[:150]}"
    except Exception as e:
        return f"âŒ í†µì‹  ì¥ì• : {str(e)}"

def get_pdf_text(pdf_url):
    try:
        res = requests.get(pdf_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=20)
        with fitz.open(stream=BytesIO(res.content), filetype="pdf") as doc:
            # í…ìŠ¤íŠ¸ê°€ í’ë¶€í•œ ì• 3í˜ì´ì§€ë¥¼ ì¶”ì¶œ
            return "".join([p.get_text() for p in doc[:3]])
    except: return ""

async def main():
    bot = telegram.Bot(token=TELEGRAM_TOKEN)
    # ì‚°ì—…(industry)ê³¼ ì‹œì¥(market) ë¦¬í¬íŠ¸ë¥¼ ëª¨ë‘ ìˆœíšŒí•©ë‹ˆë‹¤.
    targets = [{"n":"ì‚°ì—…", "i":"ğŸ—ï¸", "t":"industry"}, {"n":"ì‹œì¥", "i":"ğŸ“ˆ", "t":"market"}]
    
    print("ğŸš€ [í•œêµ­ ê³„ì • í…ŒìŠ¤íŠ¸] ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ë° ìš”ì•½ ì‹œì‘...")
    
    for cat in targets:
        url = f"https://consensus.hankyung.com/analysis/list?skinType={cat['t']}"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ê²Œì‹œíŒ ìµœìƒë‹¨ ë¦¬í¬íŠ¸ 1ê°œì”©ë§Œ í…ŒìŠ¤íŠ¸ ë°œì†¡
        row = soup.select('tr')[1]
        cols = row.find_all('td')
        if len(cols) < 5: continue
        
        a_tag = row.find('a', href=re.compile(r'report_idx='))
        title = a_tag.get_text(strip=True)
        
        # ì¶œì²˜(ì¦ê¶Œì‚¬) ì¶”ì¶œ: ìˆ«ìê°€ ì—†ëŠ” ë¬¸ìì—´ ì¹¸ì„ ìš°ì„  ì„ íƒ
        provider = "ì¶œì²˜ë¯¸ìƒ"
        for i in [4, 5, 3]:
            val = cols[i].get_text(strip=True)
            if val and not any(x.isdigit() for x in val.replace('.','')):
                provider = val
                break
        
        full_link = BASE_URL + a_tag['href'] if a_tag['href'].startswith('/') else a_tag['href']
        
        print(f"[{cat['n']}] {title} ì²˜ë¦¬ ì¤‘...")
        pdf_text = get_pdf_text(full_link)
        summary = get_summary_rest(pdf_text)
        
        msg = (f"<b>{cat['i']} {cat['n']} ë¦¬í¬íŠ¸ ë„ì°©</b>\n\n"
               f"ì¶œì²˜: <b>{provider}</b>\n"
               f"ì œëª©: {title}\n"
               f"--------------------------\n"
               f"{summary}\n"
               f"--------------------------\n"
               f"<a href='{full_link}'>ğŸ‘‰ ë¦¬í¬íŠ¸ ì›ë¬¸ ë³´ê¸°</a>")
        
        await bot.send_message(chat_id=CHAT_ID, text=msg, parse_mode='HTML', disable_web_page_preview=True)
        await asyncio.sleep(2)

if __name__ == "__main__":
    asyncio.run(main())
