import os
import requests
import telegram
import asyncio
import re
import fitz  # PyMuPDF
import json
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from io import BytesIO

# --- ì„¤ì • (GitHub Secrets) ---
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

BASE_URL = "https://consensus.hankyung.com"

# í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì‚°ì—…ê³¼ ì‹œì¥ ê°ê° ìµœì‹  3ê°œì”©ë§Œ í™•ì¸
TARGET_CATEGORIES = [
    {"name": "ì‚°ì—…", "icon": "ğŸ—ï¸", "type": "industry"},
    {"name": "ì‹œì¥", "icon": "ğŸ“ˆ", "type": "market"}
]

# --- Gemini REST API (ê°€ì¥ ì•ˆì •ì ì¸ í˜¸ì¶œ ë°©ì‹) ---
def get_summary_rest(text):
    if not GEMINI_API_KEY: return "âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # 404 ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ ì •ì„ì ì¸ Endpoint (v1 ë²„ì „ ì‚¬ìš©)
    url = f"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    headers = {'Content-Type': 'application/json'}
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    clean_text = text[:8000].replace('"', "'")
    prompt = f"ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¦¬í¬íŠ¸ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ íˆ¬ììê°€ í•µì‹¬ì ìœ¼ë¡œ íŒŒì•…í•´ì•¼ í•  ë‚´ìš© 3ê°€ì§€ë¥¼ ì „ë¬¸ì ì¸ ì–´ì¡°ë¡œ ìš”ì•½í•˜ì„¸ìš”:\n\n{clean_text}"
    
    payload = {
        "contents": [{
            "parts": [{"text": prompt}]
        }]
    }
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=30)
        
        if response.status_code == 200:
            res_data = response.json()
            return res_data['candidates'][0]['content']['parts'][0]['text'].strip()
        else:
            # ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸ ì‘ë‹µ ë‚´ìš©ì„ í•¨ê»˜ ë°˜í™˜í•˜ì—¬ ì›ì¸ íŒŒì•…
            return f"âŒ API ì˜¤ë¥˜ (Code: {response.status_code})\nìƒì„¸ë‚´ìš©: {response.text[:100]}"
    except Exception as e:
        return f"âŒ í†µì‹  ì˜¤ë¥˜: {str(e)}"

def get_pdf_text(pdf_url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(pdf_url, headers=headers, timeout=30)
        with fitz.open(stream=BytesIO(response.content), filetype="pdf") as doc:
            full_text = ""
            # ë¶„ì„ì„ ìœ„í•´ ì• 3í˜ì´ì§€ë§Œ ì¶”ì¶œ
            for page in doc[:3]:
                full_text += page.get_text()
            return full_text
    except Exception as e:
        print(f"PDF ì¶”ì¶œ ì—ëŸ¬: {e}")
        return ""

async def main():
    bot = telegram.Bot(token=TELEGRAM_TOKEN)
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}

    print("ğŸš€ ìˆ˜ë™ ìš”ì•½ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì¤‘ë³µ ì²´í¬ ë¬´ì‹œ)")
    
    for cat in TARGET_CATEGORIES:
        print(f"ğŸ” {cat['name']} ì¹´í…Œê³ ë¦¬ ìµœì‹  ë¦¬í¬íŠ¸ ì¡°íšŒ ì¤‘...")
        url = f"https://consensus.hankyung.com/analysis/list?skinType={cat['type']}"
        
        try:
            res = requests.get(url, headers=headers, timeout=15)
            soup = BeautifulSoup(res.text, 'html.parser')
            rows = soup.find_all('tr')[1:4] # ìƒë‹¨ ê³µì§€ ì œì™¸ ìµœì‹  3ê°œë§Œ í…ŒìŠ¤íŠ¸
            
            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 5: continue
                
                a_tag = row.find('a', href=re.compile(r'report_idx='))
                if not a_tag: continue
                
                title = a_tag.get_text(strip=True)
                
                # ì¶œì²˜(ì¦ê¶Œì‚¬) ì¶”ì¶œ - ì—¬ëŸ¬ ì¹¸ ì¤‘ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê³³ íƒìƒ‰
                provider = "ì¶œì²˜ë¯¸ìƒ"
                for i in [4, 5, 3]:
                    val = cols[i].get_text(strip=True)
                    if val and val.count('.') < 2 and not val.isdigit():
                        provider = val
                        break
                
                full_link = BASE_URL + a_tag['href'] if a_tag['href'].startswith('/') else a_tag['href']
                
                print(f"ğŸ“ [{provider}] {title} ìš”ì•½ ì‹œë„ ì¤‘...")
                
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ìš”ì•½
                pdf_text = get_pdf_text(full_link)
                summary = get_summary_rest(pdf_text) if len(pdf_text) > 100 else "âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"
                
                # ë©”ì‹œì§€ êµ¬ì„±
                msg = (f"<b>{cat['icon']} {cat['name']} ë¦¬í¬íŠ¸ (ìˆ˜ë™ í…ŒìŠ¤íŠ¸)</b>\n\n"
                       f"ì¶œì²˜: <b>{provider}</b>\n"
                       f"ì œëª©: {title}\n"
                       f"--------------------------\n"
                       f"{summary}\n"
                       f"--------------------------\n"
                       f"<a href='{full_link}'>ğŸ‘‰ ë¦¬í¬íŠ¸ ì›ë¬¸ ë³´ê¸°</a>")
                
                await bot.send_message(chat_id=CHAT_ID, text=msg, parse_mode='HTML', disable_web_page_preview=True)
                print(f"âœ… ì „ì†¡ ì™„ë£Œ: {title}")
                await asyncio.sleep(1) # ì „ì†¡ ì†ë„ ì œí•œ

        except Exception as e:
            print(f"âŒ {cat['name']} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")

    print("ğŸ ëª¨ë“  ë¦¬í¬íŠ¸ ì²˜ë¦¬ ì™„ë£Œ")

if __name__ == "__main__":
    asyncio.run(main())
