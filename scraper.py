import os
import requests
import telegram
import asyncio
import re
import fitz
import json
from bs4 import BeautifulSoup
from io import BytesIO

# --- ì„¤ì • ---
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
BASE_URL = "https://consensus.hankyung.com"

def get_summary_rest(text):
    if not GEMINI_API_KEY: return "âŒ í‚¤ ë¯¸ì„¤ì •"
    
    # [ìµœì¢… ìˆ˜ì •] 404 ë°©ì§€ë¥¼ ìœ„í•´ v1 ì •ì‹ ë²„ì „ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
    url = f"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    
    headers = {'Content-Type': 'application/json'}
    payload = {
        "contents": [{
            "parts": [{"text": f"ë‹¤ìŒ ê¸ˆìœµ ë¦¬í¬íŠ¸ë¥¼ 3ê°€ì§€ í•µì‹¬ ìš”ì ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:\n\n{text[:7000]}"}]
        }]
    }
    
    try:
        res = requests.post(url, headers=headers, json=payload, timeout=20)
        
        # ë§Œì•½ v1ì—ì„œ 404ê°€ ë‚˜ë©´ v1betaë¡œ í•œ ë²ˆ ë” ì‹œë„ (ìë™ ì „í™˜)
        if res.status_code == 404:
            url_beta = url.replace("/v1/", "/v1beta/")
            res = requests.post(url_beta, headers=headers, json=payload, timeout=20)
            
        if res.status_code == 200:
            return res.json()['candidates'][0]['content']['parts'][0]['text'].strip()
        else:
            return f"âŒ ìš”ì•½ ì‹¤íŒ¨ (Code {res.status_code})\nì—ëŸ¬: {res.text[:100]}"
    except Exception as e:
        return f"âŒ í†µì‹  ì˜¤ë¥˜: {str(e)}"

def get_pdf_text(pdf_url):
    try:
        # ë¦¬í¬íŠ¸ ì›ë¬¸ ì ‘ì†ì„ ìœ„í•œ í—¤ë”
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        res = requests.get(pdf_url, headers=headers, timeout=20)
        with fitz.open(stream=BytesIO(res.content), filetype="pdf") as doc:
            return "".join([p.get_text() for p in doc[:3]])
    except: return ""

async def main():
    bot = telegram.Bot(token=TELEGRAM_TOKEN)
    # ì‚°ì—…(industry)ê³¼ ì‹œì¥(market) ëª¨ë‘ ì¶”ì 
    targets = [{"n":"ì‚°ì—…", "i":"ğŸ—ï¸", "t":"industry"}, {"n":"ì‹œì¥", "i":"ğŸ“ˆ", "t":"market"}]
    
    print("ğŸš€ ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ë° ìš”ì•½ ì‹œì‘ (ìˆ˜ë™ ì‹¤í–‰)")
    
    for cat in targets:
        url = f"https://consensus.hankyung.com/analysis/list?skinType={cat['t']}"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ìµœì‹  2ê°œì”©ë§Œ í…ŒìŠ¤íŠ¸
        rows = soup.select('tr')[1:3] 
        
        for row in rows:
            cols = row.find_all('td')
            if len(cols) < 5: continue
            
            a_tag = row.find('a', href=re.compile(r'report_idx='))
            if not a_tag: continue
            
            title = a_tag.get_text(strip=True)
            
            # ì¶œì²˜(ì¦ê¶Œì‚¬) ì°¾ê¸°: ìˆ«ì/ë‚ ì§œê°€ ì•„ë‹Œ ì¹¸ì„ ìš°ì„  ì„ íƒ
            provider = "ì¶œì²˜ë¯¸ìƒ"
            for i in [4, 5, 3]:
                val = cols[i].get_text(strip=True)
                if val and not any(x.isdigit() for x in val.replace('.','')):
                    provider = val
                    break
            
            full_link = BASE_URL + a_tag['href'] if a_tag['href'].startswith('/') else a_tag['href']
            
            # ìš”ì•½ ì§„í–‰
            pdf_text = get_pdf_text(full_link)
            summary = get_summary_rest(pdf_text) if len(pdf_text) > 100 else "âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¶ˆê°€"
            
            msg = (f"<b>{cat['i']} {cat['n']} ë¦¬í¬íŠ¸</b>\n\n"
                   f"ì¶œì²˜: <b>{provider}</b>\n"
                   f"ì œëª©: {title}\n"
                   f"--------------------------\n"
                   f"{summary}\n"
                   f"--------------------------\n"
                   f"<a href='{full_link}'>ğŸ‘‰ ë¦¬í¬íŠ¸ ì›ë¬¸ ë³´ê¸°</a>")
            
            await bot.send_message(chat_id=CHAT_ID, text=msg, parse_mode='HTML', disable_web_page_preview=True)
            await asyncio.sleep(1)

if __name__ == "__main__":
    asyncio.run(main())
