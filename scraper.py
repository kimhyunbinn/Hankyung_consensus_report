import os
import requests
import telegram
import asyncio
import re
import fitz  # PyMuPDF
import json
from bs4 import BeautifulSoup
from io import BytesIO

# --- ì„¤ì • (GitHub Secrets) ---
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

BASE_URL = "https://consensus.hankyung.com"

TARGET_CATEGORIES = [
    {"name": "ì‚°ì—…", "icon": "ğŸ—ï¸", "type": "industry"},
    {"name": "ì‹œì¥", "icon": "ğŸ“ˆ", "type": "market"}
]

# --- Gemini API (404 ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ ê²½ë¡œ ìˆ˜ì •) ---
def get_summary_rest(text):
    if not GEMINI_API_KEY: return "âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # [ì¤‘ìš” ìˆ˜ì •] v1beta1 ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³€ê²½í•˜ì—¬ ëª¨ë¸ ì¸ì‹ë¥ ì„ ë†’ì„
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    
    headers = {'Content-Type': 'application/json'}
    
    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ë¶ˆí•„ìš”í•œ ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°)
    clean_text = text[:8000].replace('"', "'").replace('\n', ' ')
    prompt = f"ê¸ˆìœµ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ë¦¬í¬íŠ¸ì˜ í•µì‹¬ íˆ¬ì í¬ì¸íŠ¸ 3ê°€ì§€ë¥¼ ìš”ì•½í•´ì¤˜. í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡°ë¥¼ ì‚¬ìš©í•´:\n\n{clean_text}"
    
    # [ìˆ˜ì •] êµ¬ê¸€ API í‘œì¤€ í˜ì´ë¡œë“œ êµ¬ì¡°
    payload = {
        "contents": [{
            "parts": [{"text": prompt}]
        }],
        "generationConfig": {
            "temperature": 0.2,
            "topP": 0.8,
            "topK": 40
        }
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            res_data = response.json()
            return res_data['candidates'][0]['content']['parts'][0]['text'].strip()
        else:
            # ì—¬ì „íˆ ì—ëŸ¬ê°€ ë‚œë‹¤ë©´ ìƒì„¸ ë‚´ìš©ì„ ì¶œë ¥
            return f"âŒ API ì˜¤ë¥˜ (Code: {response.status_code})\në©”ì‹œì§€: {response.text[:200]}"
    except Exception as e:
        return f"âŒ í†µì‹  ì˜¤ë¥˜: {str(e)}"

def get_pdf_text(pdf_url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(pdf_url, headers=headers, timeout=30)
        with fitz.open(stream=BytesIO(response.content), filetype="pdf") as doc:
            full_text = ""
            # ë³¸ë¬¸ íŒŒì•…ì„ ìœ„í•´ 1~3í˜ì´ì§€ ì¶”ì¶œ
            for page in doc[:3]:
                full_text += page.get_text()
            return full_text
    except:
        return ""

async def main():
    bot = telegram.Bot(token=TELEGRAM_TOKEN)
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}

    print("ğŸš€ [ìˆ˜ë™ ëª¨ë“œ] ìµœì‹  ë¦¬í¬íŠ¸ ë°œì†¡ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    for cat in TARGET_CATEGORIES:
        # ê° ì¹´í…Œê³ ë¦¬ ê²Œì‹œíŒ ì ‘ì†
        url = f"https://consensus.hankyung.com/analysis/list?skinType={cat['type']}"
        try:
            res = requests.get(url, headers=headers, timeout=15)
            soup = BeautifulSoup(res.text, 'html.parser')
            # ìƒë‹¨ ê³µì§€ì‚¬í•­ì„ ì œì™¸í•œ ì‹¤ì œ ìµœì‹  ë¦¬í¬íŠ¸ 3ê°œë§Œ ì„ íƒ
            rows = soup.select('tr')[1:4] 
            
            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 5: continue
                
                a_tag = row.find('a', href=re.compile(r'report_idx='))
                if not a_tag: continue
                
                title = a_tag.get_text(strip=True)
                
                # [ì¶œì²˜ ì°¾ê¸°] ìˆ«ìê°€ í¬í•¨ë˜ì§€ ì•Šì€ í…ìŠ¤íŠ¸ ì¹¸ì„ ì¦ê¶Œì‚¬ë¡œ íŒë‹¨
                provider = "ì¶œì²˜ë¯¸ìƒ"
                for i in [4, 5, 3]:
                    val = cols[i].get_text(strip=True)
                    if val and not any(c.isdigit() for c in val.replace('.','')):
                        provider = val
                        break
                
                full_link = BASE_URL + a_tag['href'] if a_tag['href'].startswith('/') else a_tag['href']
                
                print(f"ğŸ” [{provider}] {title} ìš”ì•½ ì‹œë„ ì¤‘...")
                
                # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ìš”ì•½ ìˆ˜í–‰
                pdf_text = get_pdf_text(full_link)
                summary = get_summary_rest(pdf_text) if len(pdf_text) > 100 else "âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"
                
                msg = (f"<b>{cat['icon']} {cat['name']} ë¦¬í¬íŠ¸ (ìˆ˜ë™ í…ŒìŠ¤íŠ¸)</b>\n\n"
                       f"ì¶œì²˜: <b>{provider}</b>\n"
                       f"ì œëª©: {title}\n"
                       f"--------------------------\n"
                       f"{summary}\n"
                       f"--------------------------\n"
                       f"<a href='{full_link}'>ğŸ‘‰ ë¦¬í¬íŠ¸ ì›ë¬¸ ë³´ê¸°</a>")
                
                await bot.send_message(chat_id=CHAT_ID, text=msg, parse_mode='HTML', disable_web_page_preview=True)
                await asyncio.sleep(2) # ì „ì†¡ ê°„ê²© ìœ ì§€

        except Exception as e:
            print(f"âŒ {cat['name']} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    print("ğŸ ëª¨ë“  ë¦¬í¬íŠ¸ ì „ì†¡ ì™„ë£Œ")

if __name__ == "__main__":
    asyncio.run(main())
