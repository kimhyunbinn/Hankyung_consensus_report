import os
import requests
import telegram
import asyncio
import re
import fitz
from bs4 import BeautifulSoup
from io import BytesIO
from datetime import datetime

# --- ì„¤ì • (GitHub Secrets) ---
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
BASE_URL = "https://consensus.hankyung.com"

def get_summary(text):
    if not GEMINI_API_KEY: return "âŒ í‚¤ ë¯¸ì„¤ì •"
    
    # ì„±ê³µí–ˆë˜ ìµœì‹  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (ì„±ê³µí•œ ëª¨ë¸ì„ ê°€ì¥ ì•ì— ë‘ì„¸ìš”)
    models_to_try = ["gemini-2.5-flash", "gemini-2.0-flash", "gemini-1.5-flash-latest"]
    
    for model in models_to_try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={GEMINI_API_KEY}"
        
        # 5ê°€ì§€ í¬ì¸íŠ¸ë¥¼ ìš”êµ¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
        payload = {
            "contents": [{"parts": [{"text": f"ë„ˆëŠ” ê¸ˆìœµ ì „ë¬¸ê°€ì•¼. ë‹¤ìŒ ë¦¬í¬íŠ¸ ë‚´ìš©ì„ ë¶„ì„í•´ì„œ íˆ¬ììê°€ ê¼­ ì•Œì•„ì•¼ í•  í•µì‹¬ ë‚´ìš©ì„ ë°˜ë“œì‹œ 5ê°œì˜ ë¶ˆë ›í¬ì¸íŠ¸(*)ë¡œ ìš”ì•½í•´ì¤˜. í•œêµ­ì–´ë¡œ ì‘ì„±í•´:\n\n{text[:8000]}"}]}]
        }
        
        try:
            res = requests.post(url, json=payload, timeout=20)
            if res.status_code == 200:
                return res.json()['candidates'][0]['content']['parts'][0]['text'].strip()
            continue 
        except:
            continue
            
    return "âŒ ìš”ì•½ ì‹¤íŒ¨ (ëª¨ë¸ í™•ì¸ í•„ìš”)"

def get_pdf_text(pdf_url):
    try:
        res = requests.get(pdf_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=20)
        with fitz.open(stream=BytesIO(res.content), filetype="pdf") as doc:
            return "".join([p.get_text() for p in doc[:3]])
    except: return ""

async def main():
    bot = telegram.Bot(token=TELEGRAM_TOKEN)
    targets = [{"n":"ì‹œì¥", "i":"ğŸ“ˆ", "t":"market"}, {"n":"ì‚°ì—…", "i":"ğŸ—ï¸", "t":"industry"}]
    
    # ì˜¤ëŠ˜ ë‚ ì§œ (YYYY.MM.DD)
    today_str = datetime.now().strftime("%Y.%m.%d")
    
    for cat in targets:
        url = f"{BASE_URL}/analysis/list?skinType={cat['t']}"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')
        
        row = soup.select('tr')[1]
        cols = row.find_all('td')
        if len(cols) < 5: continue
        
        a_tag = row.find('a', href=re.compile(r'report_idx='))
        title = a_tag.get_text(strip=True)
        
        # ì¦ê¶Œì‚¬(ì¶œì²˜) ì¶”ì¶œ
        provider = "ì¶œì²˜ë¯¸ìƒ"
        for i in [4, 5, 3]:
            val = cols[i].get_text(strip=True)
            if val and not any(x.isdigit() for x in val):
                provider = val
                break
        
        full_link = BASE_URL + a_tag['href'] if a_tag['href'].startswith('/') else a_tag['href']
        
        # ìš”ì•½ ìˆ˜í–‰
        summary_content = get_summary(get_pdf_text(full_link))
        
        # ë©”ì‹œì§€ ì–‘ì‹ ì¡°ë¦½
        msg = (f"{cat['i']} <b>{cat['n']} ë¦¬í¬íŠ¸</b>\n\n"
               f"ì¶œì²˜: <b>{provider}</b>\n"
               f"ì œëª©: {title}\n"
               f"({today_str})\n"
               f"--------------------------\n"
               f"âœ… <b>í•µì‹¬ ë‚´ìš© ìš”ì•½</b>\n"
               f"{summary_content}\n"
               f"--------------------------\n"
               f"<a href='{full_link}'>ğŸ‘‰ ì›ë¬¸ ë³´ê¸°</a>")
        
        await bot.send_message(chat_id=CHAT_ID, text=msg, parse_mode='HTML', disable_web_page_preview=True)
        await asyncio.sleep(2)

if __name__ == "__main__":
    asyncio.run(main())
